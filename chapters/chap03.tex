\chapter{Revival and Recent Explosion}

In 2007 \cite{hinton2009deep} published his paper on "Deep Belief Networks"; a layered composite model that was used in image recognition. 
However, the approach still suffered from several limitations. Firstly, using Hinton's method of backpropagation was promising, but the deep belief nets at the time still suffered from what is known as "vanishing gradients". The error that was backpropagated through the network to adjust all parameters grew vanishingly small after propagation through multiple layers - due to the fact that backpropagation involved multiple multiplications by numbers between 0 and 1.

This was due to the fact that backpropagation builds a partial derivative of the loss function with regard to each weight, which was in relation to the slope of the activation function. The most popular activation function at the time, the \textit{sigmoid} activation function, has a gradient approaching 0 at large and small values. This leads to vanishing gradients, or saturated activation functions.

At the time it was standard procedure, therefore, to pre-train lower layers of the network separately, in order adjust their weights.

In 2010 \cite{glorot2010understanding} proposed a new initialization function for weights, a normalized random activation, henceforth the de-facto standard known as glorot-initialization (which is still used by default in packages like keras). This initialization, with the advent of new activation functions such as the hyperbolic tangent activation function, significantly ameliorated the problem of saturation.

Finally in 2012, two more important pieces emerged to kick off the recent explosion off deep learning, which is still ongoing. 

\textit{Dropout} which randomly deactivates a number of neurons of a neural network layer during training in order to make sure training signals "saturate" each region and that neurons do not overfit each other's signals too closely as described by \cite{dropout} (thereby making neural networks much more robust and reduce their generalization error).

Secondly, \textit{RMSPropagation} as described by \cite{RMSPROP}, in which batches are split into smaller mini batches and adjust the change in weights based on the root mean square (hence RMS) of the batch, thereby enabling smaller batches of very large datasets being used. 

As soon as these pieces were in place, a veritable cambrian explosion of deep learning followed. Both new improvements to the approach were developed and applications of established research followed, some the most important of which are:

\begin{itemize}
	\item BatchNormalization - \cite{ioffe2015batch}
	\item Wide \& Deep learning for Recommender Systems - \cite{cheng2016wide}
	\item Generative Adversarial Networks - \cite{goodfellow2014generative}
	\item Monte-Carlo Dropout - \cite{gal2016dropout}
	\item Word Embeddings for natural language understanding - \cite{mikolov2013distributed}
	\item Recurrent Neural Networks with \ac{LSTM} for long Sequence and time-series processing - \cite{hochreiter1997long}
	\item Convolution and Max Pooling used in Neural Networks for computer vision - \cite{378228}
\end{itemize}

The advances since 2012 have kicked off a veritable tsunami of research and development of neural networks and the field itself is still very much in flux. Arguably, only a very small percentage of these advances have, in turn, as of yet found their way into application in business and public sectors at all - undoubtedly, many of these improvements will find their business models and will therefore be applied more broadly in various industries.

As for the ever-elusive promise of \textbf{true} artificial intelligence, or artificial general intelligence as it is now referred to - some researchers and public intellectuals such as Sam Harris have been very vocal about the risks of the race towards \ac{AI} which, as they argue, have fallen by the wayside. A good summary of this is his interview with Stuart Russel, co-author of "Artifitial Intelligence, a modern approach" here: \url{https://samharris.org/podcasts/the-dawn-of-artificial-intelligence1/}. 

Others like \cite{thousand} in his book "a thousand brains" argue that while \ac{AI} is coming, it is not cause for alarm, simply because the analogy towards the brain does not completely hold. 

While Geoffrey Hinton himself apparently stated that deep networks alone may not be enough for true \ac{AI} and we need to look towards other ways than backpropagation such as reinforcement learning, transfer learning, genetic algorithms, one-shot learning and other approaches.

In his recent interview with Lex Fridman (\url{https://lexfridman.com/peter-norvig/}), Peter Norvig (himself co-author of "Artificial Intelligence: A modern Approach" together with Steward Russel and others, \cite{russell2002artificial} ) contrasted the more "probabilistic" approach modeled in deep learning to expert systems based on booleans and binary logic employed in expert systems and noted that for true \ac{AI} a synthesis of the two would probably be necessary.

Similarly, Ian Goodfellow (creator of \acp{GAN}) pointed out that while especially \ac{LSTM} provided something like an internal representation of "knowledge" in a \ac{nn}, effectively propagating forward the signal as it is done in the \ac{LSTM} approach does not actually model short-term memory as it is defined in the brain - he therefore also noted that \acp{nn} would have to interact with or completely incorporate a knowledge base in some way (interview found here: \url{https://lexfridman.com/ian-goodfellow/}).

While some very promising results have been achieved in steps relating to perception and multi-step processing of multidimensional data in \acp{nn}, the search for true \ac{AI} seems to be missing some fundamental ingredients. Maybe even in the practical application of a theoretically explored approach from decades ago that is simply waiting for its' revival.

It may therefore be taken for granted that the field itself will remain dynamic and vibrant for years to come, even though another \ac{AI} winter is not out of the realm of possibility - see \cite{schuchmann2019analyzing}.
